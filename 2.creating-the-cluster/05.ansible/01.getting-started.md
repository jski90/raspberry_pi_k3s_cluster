We have no gotten logged into each of our nodes and configured our OS for all of them as well, congrats to you!  Before we can get plugging away with Ansible, there are some things we need to take care of first, **make sure you are logged into your "master" node for this step and logged into root user**:

**Step 1.** Navigate to our hosts file by using the command **cd /etc**

**Step 2.** Inside the /etc directory, we can use the command **ls -l** which will list all files within the directory (that aren't hidden, which we can use a different command for that, which we will cover later)

**Step 3.** Looking through your files, you should see a file named **hosts**, we will use the built-in editor "nano" to alter this file.  If you prefer to use a different editor, you're obviously more than welcome to do so.  The command should look like: **nano hosts**

**Step 4.** This will bring up the editor for the **hosts** file, we will be making some entries into this file, which will be as follows:

IP_FOR_MASTER_NODE MASTER_NODE_NAME MASTER_NODE_NAME.local **spaces inbetween each entry**

IP_FOR_WORKER_NODE WORKER_NODE_NAME WORKER_NODE_NAME.local **spaces inbetween each entry**

**We will repeat the worker node entry into the hosts file for all worker nodes that you have for your cluster. EX: If you have 1 master and 3 workers you should be adding 4 entries to this file in total.** 

Obviously you want to add the information that fits your nodes, which can vary depenidng on the IP addresses and naming convention you picked for your cluster.

**Step 5.** If you are new to "nano", to save and exit you will press **Ctrl+X, then Y, then Enter**.  That will save the modified buffer, confirm the file name, and exit the editor

**Step 6.** Now we will do the fun part of installing Ansible by running the command: **apt install ansible**.  This should be a relatively quick install (a few minutes), and you will be prompted that the install will use XXXmb of additional disk space, so make sure you press **y and then Enter** to confirm

**Step 7.** After install shows complete, you can use the command **ansible --version** to verify everything went smoothly, and this will also show you the version of ansible you have installed

**Step 8.** We will now navigate to the **/etc** directory by using **cd /etc**, at this point we will need to create the directory **ansible** by using the command **mkdir ansible** and then change directory into it by using **cd ansible**.  At this point, we will create a local **hosts** file by using the command **nano hosts**.  Within this file we will add the following information:

[control]
MASTER_NODE_NAME  ansible_connection=local

[workers]
WORKER_NODE_NAME  ansible_connection=ssh

[cube:children]
control
workers

**Use the name for your master node and worker node(s).  If you have more than 1 worker node, just duplicate that line underneath the workers group and update the names accordingly.  The ansible_connection=ssh will still be the entry for all worker nodes**

There are 3 groups used here, [control] [workers] and [cube].   Essentially, we will use this to identify for multi-node command execution and we also have a "catch-all" group that encompasses both master and workers if we need.  The master node (the one we just installed Ansible on) will have an **ansible_connection=local** because we don't want it to attempt to SSH into itself.  However, we will need our master node to be able to SSH into our worker nodes so we can utilize multi-node commands.

**Step 9.** We will now set up an SSH key for our master node to be able to SSH into our worker nodes without the need of a password, this is optional but will help make things move along much more smoothly so I would highly recommend it.  **Make sure you are the root user for this portion, if you are logged in under the dietpi user, you can use command sudo su - to switch to root**.  We will use the **cd** command to change to the home directory, we will then use the **ls -al** command and look for the **.ssh** directory near the top.  If you do not have the **.ssh** directory, then you can create it by using **mkdir ~/.ssh**, if you already have the **.ssh** directory then that command isn't necessary.  

**Step 10.** We will then use the **ssh-keygen -t rsa** command to generate an ssh key, you will be prompted to save in the default storage path which should be the **.ssh** directory, you can choose to use a passphrase as well if you would like.  You will get a confirmation that the key has been generated.

**Step 11.** We now need to copy over our SSH key to the worker nodes, I couldn't find a command to do this, unfortunately.  Even the **ssh-copy-id** command couldn't sort it out.  It seems as though with the DietPi installation, we don't get the creation of the **authorized_keys** file so we have to manually create it.  We will log into each node and navigate to the **cd /root/.ssh** folder and then create an **authorized_keys** file where we will manually copy the key generated on our master node in the **id_rsa.pub** file.  You can have multiple command prompt windows open at the same time to aid in this process, and if you know of a more efficient way to do this pelase let me know!

**Step 12.** 
